# learning-and-research-accelerator

Tool framework for Symbiotic Intelligence - with the goal of facilitating learning and research in both man and machine.


## End Design Goal: 

Create a tool framework around the "principle of emergence"* to enable the "symbiotic relationship between man and machine"* to be "more than the sum of its parts" - or Symbiotic Intelligence - to improve accelleration of productivity, reduction of error, increased output, faster decision management with better information, and more.


### References for "principle of emergence"
  * https://www.sebokwiki.org/wiki/Emergence ['As defined by Checkland, emergence is “the principle that entities exhibit properties which are meaningful only when attributed to the whole, not to its parts.” ' (Checkland 1999, 314).]

  * Checkland, P. 1999. Systems Thinking, Systems Practice. New York, NY, USA: John Wiley & Sons. 

  * [The sky’s the limit: why together we’re greater than the sum of our parts](https://www.theguardian.com/books/2020/feb/15/the-skys-the-limit-why-together-we-are-greater-than-the-sum-of-our-parts)

  * [Team: are you more than the sum of your parts?](https://medium.com/corporate-strategy/team-are-you-more-than-the-sum-of-your-parts-db9e98f9b836)

### Reference for "Symbiotic relationship between man and machine"
“Symbiotic relationship of Man and Machine in Space Colonization”, in the proceedings of Space Technology and Applications International Forum-2007, Roy Nielsen, AIP Conference Proceedings 880, Melvile, New York, 2007 pp. 888-896

 
## Potential other projects to pull into this project, or attempt to integrate with, or make a "Alara" plugin for:

The intent is for the App to provide a front end, glue logic, apis, plugin environment, pulling in a variety of search algorithms, libraries, frameworks and applications to facilitate accelleration of research and learning.

Integrated | Library/App/Framework | link
--- | --- | ---
not yet | scrapy - network/web scraping |  https://www.datacamp.com/tutorial/making-web-crawlers-scrapy-python , https://github.com/scrapy/scrapy
not yet | dynamic programming based search algorithms | many, one specific project -  https://github.com/junegunn/fzf
not yet | Use this static framework to create a dynamic search environment, that collects, tracks and houses biblographical information on searches in zotero - perhaps more in the future... | https://github.com/whiskyechobravo/kerko
not yet | npe2 (or similar plugin framework - but this is already in python)  | https://github.com/napari/npe2
not yet | Zotero | https://github.com/zotero/zotero
not yet | ck/cm frameworks | https://ck.readthedocs.io/en/latest/src/introduction.html , https://github.com/mlcommons/ck
not yet | plantUML | 
not yet | mermaid | 
not yet | kroki | 
not yet | drawio | https://github.com/jgraph/drawio
not yet | vym | https://github.com/insilmaril/vym
not yet | discord | https://github.com/discord
not yet | slack | https://github.com/slackapi/python-slack-sdk

## possible project phases - or sprints

### one

Design - how could it all go together - patterns, processes, etc.  Partway done...

-- only a sprint or two - otherwise, one would be forever in this phase...

### two

Start prototyping use of initial collection as proposed in phase one

Likely a several phases, for each of alpha, beta & gold, reaching 1.0

To reach 1.0, the following must be met -

* the following must be integrated into an MVC type pattern, described in the design directory
- [ ] Bibliography database integration - if possible, Zotero - open source bibliography database software and plugins
- [ ] Interface to Bibliography database, similar to Kerko - static website based on a zotero database
- [ ] Network/web searching capability - scapy - network/web scraping
- [ ] Dynamic programming based search/sort, possibly based on fzf - awesome fast searching..
- [ ] Plugin framework, possibly based on npe2 - if not integrating npe2, a similarly functioning plugin structure for 1.0

The above will be bound with a front end, based on, or similar to Kerko, except be a dynamically generated page based on search criteria similar to google's search criteria.  Eventually many search engines will be usable or their functionality used/leveraged.  First pass search engines:

- [ ] google.com
- [ ] scholar.google.com

stretch goals:
- [ ] images.google.com
- [ ] news.google.com
- [ ] NOAA weather search
- [ ] weather underground search

### three

- [ ]  
- [ ]  
- [ ]  
- [ ]  
- [ ]  
- [ ]  
- [ ]  
- [ ]  

### four



